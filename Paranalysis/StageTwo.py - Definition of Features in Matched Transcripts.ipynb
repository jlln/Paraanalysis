{
 "metadata": {
  "name": "",
  "signature": "sha256:b64c0f28b97169ce45d946ff799dd832724c1ff16c0fe5d3b37b0c78804da0fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "For each matched transcript, describe exons, and define spliced features by start and end regions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "import sys\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "\n",
      "np.set_printoptions(threshold='nan')\n",
      "\n",
      "# directory=sys.argv[1] Note again that this has been commented out to allow the script to run in the notebook for this demonstration.\n",
      "directory='MiSeqSFPQc.csv_MiSeqNONOc.csvTranscripts/'\n",
      "\n",
      "filename_index=pandas.read_csv(directory+\"cluster_and_transcript_annotation_file_index.csv\")\n",
      "\n",
      "translation_status=pandas.read_csv(directory+\"Translation_Status.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def features(transcript):\n",
      "\n",
      "\tcluster_data=pandas.read_csv(transcript['Transcript_Clusters'])\n",
      "\tannotation_file=transcript['Transcript_Annotation']\n",
      "\tannotation_data=pandas.read_csv(annotation_file).drop('Unnamed: 0',axis=1)\n",
      "\t\n",
      "\ttxEnd=max(annotation_data['feature_end'])\n",
      "\ttxStart=min(annotation_data['feature_start'])\n",
      "\t#Make the introns explicit\n",
      "\texon_df=annotation_data[annotation_data['feature_type']==\"Exon\"]\n",
      "\texon_nucleotides=[]\n",
      "\texon_starts=[]\n",
      "\texon_ends=[]\n",
      "\t# print exon_df\n",
      "\texon_df['feature_start'].map(lambda x:exon_starts.append(x))\n",
      "\texon_df['feature_end'].map(lambda x:exon_ends.append(x))\n",
      "\t\n",
      "\tfor e in range(len(exon_starts)):\n",
      "\t\t\n",
      "\t\texon_nucleotides.extend(range(exon_starts[e],exon_ends[e]))\n",
      "\texon_nucleotides=set(exon_nucleotides)\n",
      "\ttranscript_nucleotides=set(range(txStart,txEnd))\n",
      "\tintron_nucleotides=transcript_nucleotides.difference(exon_nucleotides)\n",
      "\t\n",
      "\n",
      "\t\n",
      "\tif len(transcript_nucleotides)!=len(exon_nucleotides)+len(intron_nucleotides):\n",
      "\t\tprint\"####################length imbalance#####################\"+transcript\n",
      "\n",
      "\tintron_nucleotides=list(intron_nucleotides)\n",
      "\tintron_starts=[]\n",
      "\tintron_ends=[]\n",
      "\tintron_features=[]\n",
      "\tif len(intron_nucleotides)!=0:\n",
      "\t\tintron_nucleotides=np.sort(np.array(intron_nucleotides))\t#have to sort the intron nucleotides otherwise the splitting operation will do subtly weird things.\n",
      "\t\tintrons=np.array_split(intron_nucleotides,np.where(np.diff(intron_nucleotides)!=1)[0]+1)\n",
      "\t\t\n",
      "\t\t\n",
      "\t\tfor intron in introns:\n",
      "\t\t\tintron_starts.append(intron[0])\n",
      "\t\t\tintron_ends.append(intron[-1])\n",
      "\t\t\tintron_features.append('Intron')\n",
      "\n",
      "\n",
      "\n",
      "\t\tintron_dict={\"feature_type\":intron_features,\"feature_start\":intron_starts,\"feature_end\":intron_ends}\n",
      "\t\tintron_df=pandas.DataFrame(intron_dict)\n",
      "\t\t\n",
      "\t\tconcat=pandas.concat([annotation_data,intron_df]).sort_index(by='feature_start')\n",
      "\t\tconcat['feature_length']=concat['feature_end']-concat['feature_start']\n",
      "\t\tannotation_data=concat.copy()\n",
      "\t\t# print concat\n",
      "\t\t\n",
      "\tif annotation_data.iloc[0,2]==\"5'-UTR\":\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\tFiveUTREnd=annotation_data[annotation_data['feature_type']==\"5'-UTR\"]['feature_end'].values[0]\n",
      "\t\tThreeUTR_Start=annotation_data[annotation_data['feature_type']==\"3'-UTR\"]['feature_start'].values[0]\n",
      "\t\tThreeUTR_End=annotation_data[annotation_data['feature_type']==\"3'-UTR\"]['feature_end'].values[0]\n",
      "\n",
      "        Five_UTR_Starters=annotation_data[annotation_data['feature_start']<FiveUTREnd]\n",
      "\t\tFive_UTR_Starters['Start_Region']=\"5'-UTR\"\n",
      "\n",
      "\t\tThree_UTR_Starters=annotation_data[annotation_data['feature_start']>ThreeUTR_Start]\n",
      "\t\tThree_UTR_Starters['Start_Region']=\"3'-UTR\"\n",
      "\n",
      "\t\tCoding_Region_Starters=annotation_data[(annotation_data['feature_start']>FiveUTREnd)]\n",
      "\t\tCoding_Region_Starters=Coding_Region_Starters[Coding_Region_Starters['feature_start']<ThreeUTR_Start]\n",
      "\t\tCoding_Region_Starters['Start_Region']=\"Coding_Region\"\n",
      "\t\t\n",
      "\n",
      "\t\tfiveutr=annotation_data[annotation_data['feature_type']==\"5'-UTR\"]\n",
      "\t\t\n",
      "\t\tthreeutr=annotation_data[annotation_data['feature_type']==\"3'-UTR\"]\n",
      "\n",
      "\n",
      "\n",
      "\t\tannotation_data=pandas.concat([Five_UTR_Starters,Three_UTR_Starters,Coding_Region_Starters])\n",
      "\t\t\n",
      "\t\tFive_UTR_Enders=annotation_data[annotation_data['feature_end']<FiveUTREnd]\n",
      "\t\tFive_UTR_Enders['End_Region']=\"5'-UTR\"\n",
      "\n",
      "\t\tThree_UTR_Enders=annotation_data[annotation_data['feature_end']>ThreeUTR_Start]\n",
      "\t\tThree_UTR_Enders['End_Region']=\"3'-UTR\"\n",
      "\n",
      "\t\tCoding_Region_Enders=annotation_data[annotation_data['feature_end']>FiveUTREnd]\n",
      "\t\tCoding_Region_Enders=Coding_Region_Enders[Coding_Region_Enders['feature_end']<ThreeUTR_Start]\n",
      "\t\tCoding_Region_Enders['End_Region']=\"Coding_Region\"\n",
      "\t\t\n",
      "\n",
      "\t\t\n",
      "\t\t\n",
      "\n",
      "\t\tannotation_data=pandas.concat([Five_UTR_Enders,Three_UTR_Enders,Coding_Region_Enders,fiveutr,threeutr])\n",
      "\n",
      "\t\tannotation_data['feature_classification']=annotation_data['feature_type']+\" from \"+annotation_data['Start_Region']+\" to \"+annotation_data['End_Region']\n",
      "\t\tannotation_data[annotation_data['feature_type']==\"3'-UTR\"]['feature_classification']==\"3'-UTR\"\n",
      "\t\tannotation_data[annotation_data['feature_type']==\"5'-UTR\"]['feature_classification']==\"5'-UTR\"\n",
      "\t# if annotation_data.iloc[0,2]==\"Untranslated Transcript\":\n",
      "\telse:\t\n",
      "\t\tannotation_data['feature_classification']=annotation_data['feature_type']+\" in a ncRNA\"\n",
      "\t\t\n",
      "\n",
      "\n",
      "\tintron_data=annotation_data[annotation_data['feature_type']==\"Intron\"].reset_index()\n",
      "\tif len(intron_data)>0:\n",
      "\t\tdel intron_data['index']\n",
      "\t\tintron_data['feature_type_index']=intron_data.index+1\n",
      "\t\t\n",
      "\t\t\n",
      "\t\tintron_data_subframes=[]\n",
      "\t\tintron_subtypes=intron_data['feature_classification'].unique()\n",
      "\n",
      "\t\tfor subtype in intron_subtypes:\n",
      "\t\t\tdata=intron_data[intron_data['feature_classification']==subtype].reset_index()\n",
      "\t\t\tdel data['index']\n",
      "\t\t\tdata['feature_subtype_index']=data.index+1\n",
      "\t\t\tintron_data_subframes.append(data)\n",
      "\t\t\t\n",
      "\t\tintron_data=pandas.concat(intron_data_subframes)\n",
      "\t\t\t\n",
      "\t\n",
      "\n",
      "\texon_data=annotation_data[annotation_data['feature_type']==\"Exon\"].reset_index()\n",
      "\tif len(exon_data)>0:\n",
      "\t\tdel exon_data['index']\n",
      "\t\texon_data['feature_type_index']=exon_data.index+1\n",
      "\t\t\n",
      "\t\t\n",
      "\t\texon_data_subframes=[]\n",
      "\t\texon_subtypes=exon_data['feature_classification'].unique()\n",
      "\n",
      "\t\tfor subtype in exon_subtypes:\n",
      "\t\t\tdata=exon_data[exon_data['feature_classification']==subtype].reset_index()\n",
      "\t\t\tdel data['index']\n",
      "\t\t\tdata['feature_subtype_index']=data.index+1\n",
      "\t\t\texon_data_subframes.append(data)\n",
      "\t\t\t\n",
      "\t\texon_data=pandas.concat(exon_data_subframes)\n",
      "\t\n",
      "\tfive_utr_data=annotation_data[annotation_data['feature_type']==\"5'-UTR\"].reset_index()\n",
      "\tdel five_utr_data['index']\n",
      "\tfive_utr_data['feature_type_index']=1\n",
      "\tfive_utr_data['feature_subtype_index']=1\n",
      "\tfive_utr_data['feature_classification']=\"5'-UTR\"\n",
      "\t\n",
      "\n",
      "\tthree_utr_data=annotation_data[annotation_data['feature_type']==\"3'-UTR\"].reset_index()\n",
      "\tdel three_utr_data['index']\n",
      "\tthree_utr_data['feature_type_index']=1\n",
      "\tthree_utr_data['feature_subtype_index']=1\n",
      "\tthree_utr_data['feature_classification']=\"3'-UTR\"\n",
      "\n",
      "\tannotation_data=pandas.concat([five_utr_data,three_utr_data,exon_data,intron_data]).sort_index(by='feature_start')\n",
      "\t\n",
      "\n",
      "\tannotation_data.to_csv(annotation_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename_index.apply(features,axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "0     None\n",
        "1     None\n",
        "2     None\n",
        "3     None\n",
        "4     None\n",
        "5     None\n",
        "6     None\n",
        "7     None\n",
        "8     None\n",
        "9     None\n",
        "10    None\n",
        "11    None\n",
        "12    None\n",
        "13    None\n",
        "14    None\n",
        "...\n",
        "554    None\n",
        "555    None\n",
        "556    None\n",
        "557    None\n",
        "558    None\n",
        "559    None\n",
        "560    None\n",
        "561    None\n",
        "562    None\n",
        "563    None\n",
        "564    None\n",
        "565    None\n",
        "566    None\n",
        "567    None\n",
        "568    None\n",
        "Length: 569, dtype: object"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "This script produces an annotation file for each matched transcript, within the specified working directory. It creates a list of these files in \"cluster_and_transcript_annotation_file_index.csv\". \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}